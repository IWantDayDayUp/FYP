# ECG Foundation Model

This project focuses on building a **foundation model for ECG signals** using **Masked Autoencoding (MAE)** pre-training.

The model learns universal ECG representations from multiple datasets and can be transferred to downstream tasks such as **arrhythmia classification**.

---

## âœ¨ Project Goals

- Pre-train a generalizable ECG representation model
- Train on multiple PhysioNet databases
- Evaluate on downstream classification tasks
- Visualize reconstruction quality and learned features
- Provide a reproducible training pipeline for HPC and local environments

---

## ðŸ“‚ Project Structure

```bash
â”œâ”€ src/ecg_fm/ # Source code (Python package)
â”‚ â”œâ”€ data/ # Dataset classes and preprocessing
â”‚ â”œâ”€ models/ # MAE and downstream models
â”‚ â”œâ”€ training/ # Training loops and pipelines
â”‚ â””â”€ utils/ # Logging, environment helpers, etc.
â”œâ”€ notebooks/ # Interactive analysis and visualization
â”œâ”€ scripts/ # SBATCH / helper scripts for HPC
â”œâ”€ configs/ # Training configuration files
â”œâ”€ train_mae.py # Entry point for single-DB MAE training
â”œâ”€ .gitignore
â””â”€ README.md
```

> Note: All raw ECG datasets and training logs are excluded from GitHub.
> See `data/README.md` for dataset installation instructions.

---

## ðŸš€ Quick Start

### HPC Training Example

```bash
sbatch --partition=gpu scripts/job_train_mae.sh
```

## ðŸ“Š Results Tracking

- `train.log` â€“ training logs
- `metrics.csv` â€“ epoch loss and performance
- `best.pt` & `last.pt` â€“ checkpoints for model evaluation
- `summary.json` â€“ run configuration and environment info

Visualizations and evaluation notebooks are in `notebooks/`.

## ðŸ§± Roadmap

- Single-dataset MAE pretraining
- Multi-dataset MAE (PhysioNet)
- Downstream arrhythmia classification
- Latent feature visualization
- Performance benchmarking across datasets
- Model deployment and inferencing interface

## âœ¦ Notes

This repository is under active development.

Contributions and feedback are welcome after publication of project results.
